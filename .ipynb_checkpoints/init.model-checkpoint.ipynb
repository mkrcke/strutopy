{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dd0e8aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy.random as random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fb9818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "data = pd.read_csv('poliblogs2008.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dba91356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load corpus\n",
    "documents = corpora.MmCorpus('corpus.mm')\n",
    "dictionary = corpora.Dictionary.load('dictionary')\n",
    "# Vocabulary\n",
    "dictionary[0]\n",
    "vocab = dictionary.id2token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8522ba",
   "metadata": {},
   "source": [
    "### Ingest corpus to create documents and vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d46df0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_stm(documents, settings): \n",
    "      \n",
    "    K = settings['dim']['K']\n",
    "    V = settings['dim']['V']\n",
    "    A = settings['dim']['A']\n",
    "    N = settings['dim']['N']\n",
    "    \n",
    "    #Random initialization\n",
    "    mu = np.array([0]*(K-1))\n",
    "    sigma = np.zeros(((K-1),(K-1)))\n",
    "    diag = np.diagonal(sigma, 0)\n",
    "    diag.setflags(write=True)\n",
    "    diag.fill(20)\n",
    "    beta = random.gamma(.1,1, V*K).reshape(K,V)\n",
    "    beta = (beta.T/beta.sum(axis=1)).T\n",
    "    lambd = np.zeros((N, (K-1)))\n",
    "    \n",
    "    #turn beta into a list and assign it for each aspect\n",
    "    beta = np.repeat(list(beta),A)\n",
    "    kappa_initialized = init_kappa(documents, K, V, A, interactions=settings['kappa']['interactions'])\n",
    "    \n",
    "    #create model object\n",
    "    model = {'mu':mu, 'sigma':sigma, 'beta': beta, 'lambda': lambd, 'kappa':kappa_initialized}\n",
    "    \n",
    "    return(model)\n",
    "\n",
    "def init_kappa(documents, K, V, A, interactions): \n",
    "    # read in documents and vocab\n",
    "    flat_documents = [item for sublist in documents for item in sublist]\n",
    "    m = []\n",
    "\n",
    "    total_sum = sum(n for _, n in flat_documents)\n",
    "\n",
    "    for elem in flat_documents: \n",
    "        m.append(elem[1] / total_sum)\n",
    "\n",
    "    m = np.log(m) - np.log(np.mean(m)) #logit of m\n",
    "\n",
    "\n",
    "    #Defining parameters\n",
    "    aspectmod = A > 1 # if there is more than one topical content variable\n",
    "    if(aspectmod):\n",
    "        interact = interactions # allow for the choice to interact\n",
    "    else:\n",
    "        interact = FALSE\n",
    "\n",
    "    #Create the parameters object\n",
    "    parLength = K + A * aspectmod + (K*A)*interact\n",
    "\n",
    "    #create covariates. one element per item in parameter list.\n",
    "    #generation by type because its conceptually simpler\n",
    "    if not aspectmod & interact:\n",
    "        covar = {'k': np.arange(K),\n",
    "             'a': np.repeat(np.nan, parLength), #why parLength? \n",
    "             'type': np.repeat(1, K)}\n",
    "\n",
    "    if(aspectmod & interact == False):\n",
    "        covar = {'k': np.append(np.arange(K), np.repeat(np.nan, A)),\n",
    "                 'a': np.append(np.repeat(np.nan, K), np.arange(A)), \n",
    "                 'type': np.append(np.repeat(1, K), np.repeat(2, A))}      \n",
    "    if(interact):\n",
    "        covar = {'k': np.append(np.arange(K), np.append(np.repeat(np.nan, A), np.repeat(np.arange(K), A))),\n",
    "                 'a': np.append(np.repeat(np.nan, K), np.append(np.arange(A), np.repeat(np.arange(A), K))), \n",
    "                 'type': np.append(np.repeat(1, K), np.append(np.repeat(2, A),  np.repeat(3,K*A)))}\n",
    "\n",
    "    kappa = {'out': {'m':m,\n",
    "                     'params' : np.tile(np.repeat(0,V), (parLength, 1)),\n",
    "                     'covar' : covar\n",
    "                     #'kappasum':, why rolling sum?\n",
    "                    }\n",
    "            }\n",
    "\n",
    "    return(kappa['out'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895cb66b",
   "metadata": {},
   "source": [
    "### Make Topic Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03643f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "prevalence = 'blog'\n",
    "content = 'rating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61fb823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTopMatrix(x, data=None):\n",
    "    return(data.loc[:,x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1af31a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmat = makeTopMatrix(content, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46bed10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yvar = makeTopMatrix(content, data)\n",
    "yvar = yvar.astype('category')\n",
    "yvarlevels = set(yvar)\n",
    "betaindex = yvar.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e71cded",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = len(set(betaindex))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8400a1b1",
   "metadata": {},
   "source": [
    "# Setting control variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a16b2c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "K = 10 #settings.dim\n",
    "V = len(vocab) #settings.dim\n",
    "N = len(documents) #settings.dim\n",
    "\n",
    "interactions = True #settings.kappa\n",
    "verbose = True\n",
    "\n",
    "init_type = \"Random\" #settings.init\n",
    "ngroups = 1 #settings.ngroups\n",
    "max_em_its = 15 #settings.convergence\n",
    "emtol = 1e-5 #settings.convergence\n",
    "\n",
    "#gamma_prior=(\"Pooled\",\"L1\") # settings.gamma.prior\n",
    "#sigma_prior=0 #settings.sigma.prior\n",
    "#kappa_prior=(\"L1\",\"Jeffreys\") # settings.kappa.prior\n",
    "\n",
    "#Initialize parameters\n",
    "\n",
    "settings = {\n",
    "    'dim':{\n",
    "        'K': K, #number of topics\n",
    "        'V' :V, #number of words\n",
    "        'A' : A, #dimension of topical content\n",
    "        'N' : N,\n",
    "        'wcounts':V\n",
    "    },\n",
    "    'kappa':{\n",
    "        'interactions':True,\n",
    "        'fixedintercept': True,\n",
    "        'contrats': False,\n",
    "        'mstep': {'tol':0.01, 'maxit':5}},\n",
    "    'tau':{\n",
    "        'mode': np.nan,\n",
    "        'tol': 1e-5,\n",
    "        'enet':1,\n",
    "        'nlambda':250,\n",
    "        'lambda.min.ratio':.001,\n",
    "        'ic.k':2,\n",
    "        'maxit':1e4},\n",
    "    'init':{\n",
    "        'mode':init_type, \n",
    "        'nits':20,\n",
    "        'burnin':25,\n",
    "        'alpha':50/K,\n",
    "        'eta':.01,\n",
    "        's':.05,\n",
    "        'p':3000},\n",
    "    'convergence':{\n",
    "        'max.em.its':max_em_its,\n",
    "        'em.converge.thresh':emtol,\n",
    "        'allow.neg.change':True,},\n",
    "    'covariates':{\n",
    "        'X':xmat,\n",
    "        'betaindex':betaindex,\n",
    "        'yvarlevels':yvarlevels,\n",
    "        'formula': prevalence,},\n",
    "    'gamma':{\n",
    "        'mode':np.nan,\n",
    "        'prior':np.nan,\n",
    "        'enet':1, \n",
    "        'ic.k':2,\n",
    "        'maxits':1000,},\n",
    "    'sigma':{\n",
    "        #'prior':sigma_prior,\n",
    "        'ngroups':ngroups,},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "11ab119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stm_control(documents, vocab, settings, model=None):\n",
    "    \n",
    "    ##########\n",
    "    #Step 1: Initialize Parameters\n",
    "    ##########\n",
    "    \n",
    "    #ngroups = settings$ngroups\n",
    "    \n",
    "    if model == None:\n",
    "        model = init_stm(documents, settings) #initialize\n",
    "    else: \n",
    "        model = model\n",
    "        \n",
    "    # unpack initialized model\n",
    "    \n",
    "    mu = model['mu']\n",
    "    sigma = model['sigma']\n",
    "    lambd = model['lambda'] \n",
    "    beta = {'beta': model['beta'],\n",
    "            'kappa': model['kappa']}\n",
    "    \n",
    "    convergence = None\n",
    "    \n",
    "    #discard the old object\n",
    "    del model\n",
    "    \n",
    "    betaindex = settings['covariates']['betaindex']\n",
    "    \n",
    "    #Pull out some book keeping elements\n",
    "    ntokens = settings['dim']['wcounts']\n",
    "    betaindex = settings['covariates']['betaindex']\n",
    "    stopits = True\n",
    "    \n",
    "    ############\n",
    "    #Step 2: Run EM\n",
    "    ############\n",
    "    \n",
    "    while stopits == False:\n",
    "        #####\n",
    "        # Non-Blocked Updates\n",
    "        #####\n",
    "        t1 = time.process_time()\n",
    "\n",
    "        #run the model\n",
    "        #suffstats = estep(documents=documents, beta_index=betaindex,\n",
    "        #                 update_mu=(!is.null(mu$gamma)),\n",
    "        #                 beta$beta, lambda, mu$mu, sigma,\n",
    "        #                 verbose)\n",
    "        \n",
    "        print(\"Completed E-Step ({} seconds). \\n\".format(math.floor((time.process_time()-t1))))\n",
    "\n",
    "\n",
    "        #unpack variables \n",
    "        \n",
    "        #t1 = process_time()\n",
    "        #sigma_ss = suffstats['sigma']\n",
    "        #lambd <- suffstats['lambd']\n",
    "        #beta_ss <- suffstats['beta']\n",
    "        #bound_ss <- suffstats['bound']\n",
    "        #do the m-step\n",
    "        #mu = opt_mu(lambd=lambd,\n",
    "        #            mode=settings['gamma']['mode'],\n",
    "        #            covar=settings['covariates']['X'],\n",
    "        #            enet=settings['gamma']['enet'],ic.k=settings$gamma$ic.k,\n",
    "        #            maxits=settings['gamma']['maxits'])\n",
    "        #sigma = opt_sigma(nu=sigma_ss, lambd=lambd,\n",
    "        #                     mu=mu['mu'], sigprior=settings['sigma']['prior'])\n",
    "        #beta = opt_beta(beta_ss, beta['kappa'], settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1f6634ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "stm_control(documents, vocab, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a257303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acc3e5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from gensim.parsing.preprocessing import (remove_stopwords,\n",
    "                                          preprocess_string,\n",
    "                                          strip_numeric,\n",
    "                                          stem_text,\n",
    "                                          strip_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "978f5bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/poliblogs2008.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cc83c4",
   "metadata": {},
   "source": [
    "### textProcessor()\n",
    "Function that takes a vector of raw texts and performs basic operations. Uses the tm-package for these operations.\n",
    "\n",
    "Input is designed as a spreadsheet, where each document is in a single cell. \n",
    "- Stemming (snowballStemmer:: SnowballC)\n",
    "- Sparsity and Stopword Removal \n",
    "- Empty Document removal \n",
    "- Specified Metadata\n",
    "\n",
    "1. Strips text and removes all non-characters. \n",
    "2. Builds corpus\n",
    "3. Converts to lower case\n",
    "4. removes (custom) punctuation\n",
    "5. removes (custom) stopwords\n",
    "6. removing number \n",
    "7. stemming\n",
    "8. assigns metadata\n",
    "9. creates output (document term matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "054dd309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection \n",
    "data = data[3000:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8545157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords\n",
    "data.documents = data.documents.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c602cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove numbers\n",
    "data.documents = data.documents.apply(strip_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff07f87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punctuation\n",
    "data.documents = data.documents.apply(strip_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92c6c9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "data.documents = data.documents.apply(stem_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a730422b",
   "metadata": {},
   "source": [
    "## metadata: Additional data about the documents\n",
    "Specifically a dataframe or matrix object with number of rows equal to the number of documents and one column per meta-data type. The column names are used to label the metadata.  The metadata do not affect the text processing, but providing the metadata object insures that if documents are dropped the corresponding metadata rows are dropped as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5c84677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topical content covariate: rating\n",
    "# topical prevalence covariate: blog\n",
    "metadata = ['rating', 'blog'] \n",
    "meta = data.loc[:,metadata]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12996f1",
   "metadata": {},
   "source": [
    "## Document-Term-Matrix\n",
    "- documents: documents are stored as indexed word counts\n",
    "- vocab: indexed word vocabulary\n",
    "\n",
    "**Note**: While the output for the stm() function in R is required to be a Document-Term-Matrix, gensim relies on the bag-of-words representation of text. This might be a difference between the R implementation and the Python implementation. It has to be evaluated, whether the dtm-representation should be retained or being replaced with the BoW-representation. If so, adjustments to the algorithm are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48c6b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03643f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary and corpus\n",
    "doc_tokens = [simple_preprocess(doc) for doc in data.documents]\n",
    "dct = corpora.Dictionary(doc_tokens)\n",
    "corpus = [dct.doc2bow(doc) for doc in doc_tokens]\n",
    "\n",
    "\n",
    "# save objects\n",
    "dct.save('../data/dictionary')\n",
    "corpora.MmCorpus.serialize('../data/corpus.mm', corpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
